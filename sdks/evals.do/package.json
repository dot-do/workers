{
  "name": "evals.do",
  "version": "0.0.1",
  "description": "Evals SDK - Evaluate AI outputs systematically",
  "type": "module",
  "main": "index.ts",
  "exports": {
    ".": "./index.ts"
  },
  "author": ".do",
  "license": "MIT",
  "homepage": "https://evals.do",
  "repository": {
    "type": "git",
    "url": "https://github.com/dot-do/workers"
  },
  "bugs": {
    "url": "https://github.com/dot-do/workers/issues"
  },
  "dependencies": {
    "capnweb": "^0.2.0",
    "org.ai": "workspace:*",
    "rpc.do": "workspace:*"
  },
  "devDependencies": {
    "typescript": "^5.0.0"
  },
  "keywords": [
    "evals",
    "evaluation",
    "ai",
    "quality",
    "testing",
    "sdk",
    "workers.do",
    "llm",
    "judge",
    "benchmark",
    "metrics",
    "scoring"
  ]
}
