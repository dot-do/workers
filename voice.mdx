---
$type: Worker
$id: voice
name: voice
main: src/index.ts
compatibility_date: "2025-07-08"
account_id: b6641681fe423910342b9ffa1364c76d

# Observability
observability:
  enabled: true

# Tail Consumers
tail_consumers:
  - service: pipeline

# Custom Domain Routes
routes:
  - pattern: voice.services.do/*
    custom_domain: true

# Service Bindings
services:
  - binding: DB
    service: db

# R2 Buckets
r2_buckets:
  - binding: AUDIO
    bucket_name: voice-audio

# Pipelines
pipelines:
  - pipeline: events-realtime
    binding: pipeline

# Dispatch Namespaces
dispatch_namespaces:
  - binding: do
    namespace: do
---

# Voice AI Generation Service

**Professional voiceovers and text-to-speech (TTS) using OpenAI, ElevenLabs, and Google Cloud**

The Voice service is a multi-provider TTS microservice that generates high-quality voiceovers for various use cases including business narration, educational content, podcasts, audiobooks, and IVR systems. It supports 3 major TTS providers, 50+ languages, and multiple audio formats with automatic R2 storage and database tracking.

## Features

### Multi-Provider Support
- **OpenAI TTS** - Fast, natural voices with steerable emotions
- **ElevenLabs** - Professional voice cloning and multilingual support
- **Google Cloud TTS** - SSML support with precise prosody control

### Voice Options
- **6+ OpenAI Voices** - Alloy, Echo, Fable, Onyx, Nova, Shimmer
- **1000+ ElevenLabs Voices** - Including voice cloning
- **100+ Google Voices** - Neural2, Studio, Chirp 3 HD

### Advanced Features
- **Steerable TTS** - Control emotion, style, tone with OpenAI gpt-4o-mini-tts
- **SSML Support** - Advanced prosody control with Google Cloud TTS
- **Professional Quality** - TTS-1 (real-time) and TTS-1-HD (high quality)
- **Multi-Format** - MP3, WAV, Opus, AAC, FLAC
- **50+ Languages** - Multilingual support across all providers
- **R2 Storage** - Automatic upload and hosting of generated audio
- **Database Tracking** - Track status, metadata, URLs, and errors
- **Batch Processing** - Generate multiple voiceovers in one request

## Architecture

```
┌─────────────────┐
│  Voice Service  │
│   (RPC + HTTP)  │
└────────┬────────┘
         │
         ├─────────┐
         │         │
         ▼         ▼
    ┌────────┐ ┌────────┐
    │   DB   │ │   R2   │
    │Service │ │ Audio  │
    └────────┘ └────────┘
         │
         ▼
   ┌──────────┐
   │ Provider │
   │   APIs   │
   └──────────┘
         │
    ┌────┴────┬───────────┐
    ▼         ▼           ▼
┌────────┐ ┌──────────┐ ┌────────┐
│ OpenAI │ │ElevenLabs│ │ Google │
│  TTS   │ │   TTS    │ │  TTS   │
└────────┘ └──────────┘ └────────┘
```

## API Reference

### HTTP Endpoints

#### Health Check
```bash
GET /health
```

**Response:**
```json
{
  "status": "ok",
  "service": "voice",
  "version": "1.0.0"
}
```

#### Generate Single Voiceover
```bash
POST /generate
```

**Request Body:**
```json
{
  "text": "Welcome to our platform. Transform your business with AI.",
  "provider": "openai",
  "voice": "onyx",
  "model": "tts-1-hd",
  "format": "mp3",
  "speed": 1.0,
  "emotion": "confident and authoritative",
  "style": "professional",
  "metadata": {
    "campaign": "product-demo",
    "version": "v2"
  }
}
```

**Response:**
```json
{
  "id": "01HXYZ...",
  "status": "pending",
  "text": "Welcome to our platform...",
  "provider": "openai",
  "voice": "onyx",
  "createdAt": "2025-10-04T12:00:00Z",
  "metadata": {
    "campaign": "product-demo",
    "version": "v2"
  }
}
```

#### Generate Batch
```bash
POST /generate/batch
```

**Request Body:**
```json
{
  "voices": [
    {
      "text": "Welcome to episode 1...",
      "provider": "openai",
      "voice": "nova"
    },
    {
      "text": "This is a professional narration...",
      "provider": "elevenlabs",
      "voice": "rachel"
    }
  ],
  "metadata": {
    "project": "podcast-series",
    "season": 1
  }
}
```

**Response:**
```json
{
  "batchId": "01HXYZ...",
  "voices": [...],
  "total": 2,
  "pending": 2,
  "completed": 0,
  "failed": 0
}
```

#### Generate Test Batch
```bash
POST /generate/test
```

Generates 5 voiceovers using pre-built prompts:
- Professional business narration (OpenAI Onyx)
- Educational explainer (ElevenLabs Rachel)
- Podcast intro (OpenAI Nova)
- Audiobook excerpt (ElevenLabs Sarah)
- Customer service greeting (Google Neural2-C)

**Response:**
```json
{
  "batchId": "01HXYZ...",
  "voices": [...],
  "total": 5,
  "pending": 5,
  "completed": 0,
  "failed": 0
}
```

#### Get Voice Status
```bash
GET /voices/:id
```

**Response:**
```json
{
  "id": "01HXYZ...",
  "status": "completed",
  "text": "Welcome to our platform...",
  "provider": "openai",
  "voice": "onyx",
  "audioUrl": "https://audio.services.do/voice/2025/10/01HXYZ.mp3",
  "r2Key": "voice/2025/10/01HXYZ.mp3",
  "duration": 8.5,
  "createdAt": "2025-10-04T12:00:00Z",
  "completedAt": "2025-10-04T12:00:05Z",
  "metadata": {
    "campaign": "product-demo"
  }
}
```

#### List Available Voices
```bash
GET /voices?provider=openai
```

**Query Parameters:**
- `provider` - Filter by provider: `openai`, `elevenlabs`, `google`, or `all`

**Response:**
```json
[
  {
    "id": "alloy",
    "name": "Alloy",
    "description": "Neutral and balanced"
  },
  {
    "id": "echo",
    "name": "Echo",
    "description": "Warm and inclusive"
  }
]
```

#### List Prompt Templates
```bash
GET /prompts
```

**Response:**
```json
[
  {
    "template": {
      "name": "Professional Business Narration",
      "useCase": "Corporate video, product demo, explainer video",
      "text": "...",
      "provider": "openai",
      "voice": "onyx"
    },
    "config": {
      "text": "...",
      "provider": "openai",
      "voice": "onyx",
      "style": "professional",
      "emotion": "confident and authoritative"
    }
  }
]
```

### RPC Interface

```typescript
const voiceService = env.VOICE_SERVICE

// Generate single voiceover
const voice = await voiceService.generateVoice({
  text: 'Hello world',
  provider: 'openai',
  voice: 'alloy',
})

// Generate batch
const batch = await voiceService.generateBatch({
  voices: [
    { text: '...', provider: 'openai', voice: 'nova' },
    { text: '...', provider: 'elevenlabs', voice: 'rachel' }
  ]
})

// Generate test batch
const test = await voiceService.generateTestBatch()

// Get voice by ID
const voice = await voiceService.getVoice('01HXYZ...')
```

## Provider Comparison

| Provider | Models | Voices | Languages | Latency | Best For |
|----------|--------|--------|-----------|---------|----------|
| **OpenAI** | tts-1, tts-1-hd, gpt-4o-mini-tts | 6 voices | 50+ | ~1-2s | Fast generation, conversational AI, real-time |
| **ElevenLabs** | eleven_multilingual_v2, eleven_turbo_v2, eleven_flash_v2 | 1000+ voices | 29 | ~75ms | Audiobooks, podcasts, voice cloning |
| **Google** | Neural2, Studio, Chirp 3 HD | 100+ voices | 40+ | ~2-3s | IVR systems, assistants, SSML control |

### OpenAI TTS

**Models:**
- `tts-1` - Real-time, optimized for speed (~1s latency)
- `tts-1-hd` - High definition, optimized for quality (~2s latency)
- `gpt-4o-mini-tts` - Steerable emotions and styles

**Voices:**
- `alloy` - Neutral and balanced
- `echo` - Warm and inclusive
- `fable` - Expressive and dynamic
- `onyx` - Deep and authoritative
- `nova` - Bright and energetic
- `shimmer` - Soft and soothing

**Features:**
- Speed control: 0.25x to 4.0x (1.0 is normal)
- Steerable emotions with gpt-4o-mini-tts
- Multiple audio formats
- Multilingual support

**Best Practices:**
- Use `tts-1` for real-time applications (chatbots, assistants)
- Use `tts-1-hd` for quality (audiobooks, podcasts, videos)
- Use `gpt-4o-mini-tts` with `emotion` and `style` parameters for steerable TTS

### ElevenLabs

**Models:**
- `eleven_multilingual_v2` - High quality, 29 languages
- `eleven_turbo_v2` - Fast, optimized for latency
- `eleven_flash_v2` - Ultra-fast, 75ms latency

**Features:**
- Professional Voice Clones (PVC)
- Voice design and voice cloning
- 29 languages
- Voice settings: stability, clarity, style exaggeration
- Speaker boost for quality

**Best Practices:**
- Use `eleven_flash_v2` for real-time applications
- Use `eleven_multilingual_v2` for quality
- Adjust voice settings for fine control
- Use Professional Voice Clones for highest quality

### Google Cloud TTS

**Voices:**
- Neural2 - Balanced quality/performance
- Studio - Highest quality
- Chirp 3 HD - Latest model, best naturalness

**Features:**
- SSML support (pauses, emphasis, prosody)
- Precise pitch and speed control
- Say-as for numbers, dates, currencies
- Multiple audio encodings

**Best Practices:**
- Use SSML for advanced control
- Use Studio voices for highest quality
- Use Neural2 for balanced quality/performance
- Specify language code for non-English content

## Usage Examples

### Basic Voice Generation

```ts
// Generate simple voiceover
const result = await fetch('https://voice.services.do/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'Hello, welcome to our service!',
    provider: 'openai',
    voice: 'alloy'
  })
})

const voice = await result.json()
console.log('Voice ID:', voice.id)
console.log('Status:', voice.status)

// Check status
const status = await fetch(`https://voice.services.do/voices/${voice.id}`)
const voiceData = await status.json()
console.log('Audio URL:', voiceData.audioUrl)
```

### Professional Narration

```ts
const result = await fetch('https://voice.services.do/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'Transform your business with AI-powered automation. Our platform streamlines workflows, eliminates repetitive tasks, and empowers teams to focus on innovation.',
    provider: 'openai',
    voice: 'onyx',
    model: 'tts-1-hd',
    emotion: 'confident and authoritative',
    style: 'professional',
    speed: 1.0,
    metadata: {
      campaign: 'product-demo',
      version: 'v2'
    }
  })
})
```

### Educational Content

```ts
const result = await fetch('https://voice.services.do/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: "Let's dive into machine learning! Imagine teaching a computer to recognize patterns. Today we'll explore supervised learning, unsupervised learning, and reinforcement learning.",
    provider: 'elevenlabs',
    voice: 'rachel',
    model: 'eleven_multilingual_v2',
    emotion: 'enthusiastic and engaging',
    style: 'educational'
  })
})
```

### Podcast Episode

```ts
const result = await fetch('https://voice.services.do/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: "Hey everyone, welcome back to Tech Horizons! I'm your host, and today we have an incredible episode. We'll discuss quantum computing breakthroughs and interview a pioneer in sustainable AI.",
    provider: 'openai',
    voice: 'nova',
    model: 'tts-1',
    emotion: 'warm and welcoming',
    style: 'conversational',
    speed: 1.05
  })
})
```

### IVR System

```ts
const result = await fetch('https://voice.services.do/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'Thank you for calling TechSupport. Press 1 for account inquiries. Press 2 for technical support. Press 3 to speak with a representative.',
    provider: 'google',
    voice: 'en-US-Neural2-C',
    ssml: true,
    speed: 0.95,
    metadata: {
      system: 'ivr',
      language: 'en-US'
    }
  })
})
```

### Batch Generation

```ts
const result = await fetch('https://voice.services.do/generate/batch', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    voices: [
      {
        text: 'Episode 1: Introduction to AI',
        provider: 'openai',
        voice: 'nova'
      },
      {
        text: 'Episode 2: Machine Learning Basics',
        provider: 'openai',
        voice: 'nova'
      },
      {
        text: 'Episode 3: Deep Learning',
        provider: 'openai',
        voice: 'nova'
      }
    ],
    metadata: {
      project: 'ai-course',
      season: 1
    }
  })
})

const batch = await result.json()
console.log('Batch ID:', batch.batchId)
console.log('Total:', batch.total)
```

## SSML Examples

SSML (Speech Synthesis Markup Language) provides advanced control over speech synthesis with Google Cloud TTS.

### Basic SSML Structure

```xml
<speak>
  Welcome to our service.
  <break time="1s"/>
  Let's get started!
</speak>
```

### Pauses and Emphasis

```xml
<speak>
  Welcome to our service.
  <break time="1s"/>
  <emphasis level="strong">This is very important!</emphasis>
  <break time="500ms"/>
  Thank you for your attention.
</speak>
```

### Prosody Control

```xml
<speak>
  <prosody rate="slow" pitch="+2st">
    Speak slowly with higher pitch
  </prosody>
  <break time="500ms"/>
  <prosody rate="fast" pitch="-2st">
    Speak quickly with lower pitch
  </prosody>
</speak>
```

### Say-As (Numbers, Dates, Currencies)

```xml
<speak>
  The total is <say-as interpret-as="cardinal">12345</say-as> dollars.
  <break time="500ms"/>
  The date is <say-as interpret-as="date" format="mdy">10/4/2025</say-as>.
  <break time="500ms"/>
  The price is <say-as interpret-as="currency">$99.99</say-as>.
</speak>
```

### Combined Example

```xml
<speak>
  Welcome to <emphasis level="strong">TechSupport Solutions</emphasis>.
  <break time="1s"/>
  Your account balance is <say-as interpret-as="currency">$1,234.56</say-as>.
  <break time="500ms"/>
  <prosody rate="slow">
    Please listen carefully to the following options.
  </prosody>
  <break time="1s"/>
  Press <say-as interpret-as="cardinal">1</say-as> for billing.
  <break time="500ms"/>
  Press <say-as interpret-as="cardinal">2</say-as> for support.
</speak>
```

## Database Schema

```sql
CREATE TABLE voice_generations (
  id TEXT PRIMARY KEY,
  text TEXT NOT NULL,
  provider TEXT NOT NULL,
  voice TEXT NOT NULL,
  model TEXT,
  format TEXT NOT NULL,
  status TEXT NOT NULL,
  audio_url TEXT,
  r2_key TEXT,
  duration REAL,
  error TEXT,
  created_at TEXT NOT NULL,
  completed_at TEXT,
  metadata TEXT
);

CREATE INDEX idx_voice_generations_status ON voice_generations(status);
CREATE INDEX idx_voice_generations_created_at ON voice_generations(created_at);
CREATE INDEX idx_voice_generations_provider ON voice_generations(provider);
```

## Use Cases

### Business & Marketing
- **Product Demos** - Professional narration for product demonstrations
- **Explainer Videos** - Clear explanations of services and features
- **Corporate Training** - E-learning courses and training materials
- **Marketing Videos** - Commercials and promotional content
- **Brand Voice** - Consistent voice across all brand content

### Media & Entertainment
- **Audiobook Narration** - Professional audiobook production
- **Podcast Production** - Intro/outro and episode content
- **Character Voices** - Animation and game character voices
- **Documentary Narration** - Documentary and film narration

### Customer Service
- **IVR Systems** - Phone menu systems and automated responses
- **Customer Support** - Automated support and FAQ responses
- **Chatbot Voices** - Voice-enabled chatbots
- **Welcome Messages** - Greeting messages and announcements

### Education
- **Online Courses** - Course narration and tutorials
- **Language Learning** - Pronunciation and conversation practice
- **Accessibility** - Text-to-speech for visually impaired users
- **Educational Videos** - Explainer videos and lectures

## Best Practices

### Text Preparation
- Use clear, well-structured sentences
- Add pauses with punctuation (periods, commas)
- Spell out acronyms phonetically if needed
- Break long text into shorter segments (< 10,000 characters)
- Use natural conversational flow

### Provider Selection
- **OpenAI** - Fast, natural, good for real-time applications
- **ElevenLabs** - Best quality, voice cloning, professional narration
- **Google** - SSML control, IVR systems, precise prosody

### Voice Selection
- Test multiple voices for your use case
- Match voice to content tone (professional, casual, warm, etc.)
- Consider gender, accent, and speaking style
- Use consistent voices for brand identity

### Quality Optimization
- Use HD models for final production
- Use standard models for testing/prototyping
- Adjust speed for pacing (0.9-1.1x usually optimal)
- Use SSML for precise control (Google only)
- Add pauses for natural flow

### Error Handling
- Check status endpoint for completion
- Implement retry logic for failed generations
- Handle rate limits appropriately
- Monitor R2 storage usage

## Comparison with Other Services

| Feature | Voice (Audio) | Veo (Video) | Imagen (Image) |
|---------|---------------|-------------|----------------|
| **Output** | MP3/WAV audio | MP4 videos | PNG/JPEG images |
| **Providers** | OpenAI, ElevenLabs, Google | Google Veo 3 | Google Imagen 3, DALL-E 3 |
| **Generation Time** | 1-5 seconds | 30-60 seconds | 5-15 seconds |
| **Storage** | ~1-5 MB per minute | ~50-200 MB per video | ~1-5 MB per image |
| **Best for** | Voiceovers, podcasts, IVR | Marketing videos, demos | Social media, ads |
| **Batch Support** | ✅ Yes | ✅ Yes | ✅ Yes |

## Development

```bash
# Install dependencies
pnpm install

# Start dev server
pnpm dev

# Run tests
pnpm test

# Type check
pnpm typecheck

# Deploy
pnpm deploy
```

## Environment Variables

```bash
# .dev.vars
OPENAI_API_KEY=sk-...
ELEVENLABS_API_KEY=...
GOOGLE_CLOUD_API_KEY=...
```

## Testing

```bash
# Health check
curl https://voice.services.do/health

# Generate test batch
curl -X POST https://voice.services.do/generate/test

# List available voices
curl https://voice.services.do/voices?provider=openai

# List prompt templates
curl https://voice.services.do/prompts

# Generate single voice
curl -X POST https://voice.services.do/generate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello world",
    "provider": "openai",
    "voice": "alloy"
  }'

# Get voice status
curl https://voice.services.do/voices/01HXYZ...
```

## TODO

- [ ] Implement actual OpenAI TTS API integration
- [ ] Implement actual ElevenLabs API integration
- [ ] Implement actual Google Cloud TTS API integration
- [ ] Add audio duration calculation
- [ ] Add retry logic for failed generations
- [ ] Add webhook notifications for completion
- [ ] Add queue-based processing
- [ ] Add MCP tools for AI agent integration
- [ ] Add audio format conversion
- [ ] Add voice cloning support (ElevenLabs)
- [ ] Add SSML validation and builder UI
- [ ] Add streaming audio support
- [ ] Add rate limiting per provider
- [ ] Add cost tracking per provider

## Related Services

- **[email](/email)** - Transactional email with Resend
- **[imagen](/imagen)** - AI image generation
- **[veo](/veo)** - AI video generation
- **[podcast](/podcast)** - AI podcast generation
- **[db](/db)** - Database service
- **[gateway](/gateway)** - API gateway

---

**Service:** voice
**Version:** 1.0.0
**Status:** Experimental (TODO: API integrations)
**Domain:** voice.services.do

## Code

```typescript
/**
 * Voice AI Generation Service
 *
 * Professional voiceovers and TTS using OpenAI, ElevenLabs, and Google Cloud
 */

import { Hono } from 'hono'
import { WorkerEntrypoint } from 'cloudflare:workers'
import { ulid } from 'ulid'

// ============================================================================
// Types
// ============================================================================

export type VoiceProvider = 'openai' | 'elevenlabs' | 'google'
export type AudioFormat = 'mp3' | 'wav' | 'opus' | 'aac' | 'flac'

// OpenAI voices
export type OpenAIVoice = 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer'
export type OpenAIModel = 'tts-1' | 'tts-1-hd' | 'gpt-4o-mini-tts'

// ElevenLabs voices (examples - actual list is much larger)
export type ElevenLabsVoice = 'rachel' | 'clyde' | 'domi' | 'dave' | 'fin' | 'sarah' | 'antoni' | 'thomas' | 'charlie' | 'emily'
export type ElevenLabsModel = 'eleven_multilingual_v2' | 'eleven_turbo_v2' | 'eleven_flash_v2'

// Google voices (examples)
export type GoogleVoice = 'en-US-Neural2-A' | 'en-US-Neural2-C' | 'en-US-Neural2-D' | 'en-US-Neural2-E' | 'en-US-Neural2-F' | 'en-US-Studio-O' | 'en-US-Chirp-3-HD'

export interface Env {
  AUDIO: R2Bucket
  DB: any
  OPENAI_API_KEY: string
  ELEVENLABS_API_KEY: string
  GOOGLE_CLOUD_API_KEY: string
  pipeline: any
  do: any
}

export interface VoiceGenerationRequest {
  text: string
  provider?: VoiceProvider
  voice?: string
  model?: string
  format?: AudioFormat
  speed?: number // 0.25 to 4.0
  pitch?: number // -20 to 20 (semitones)
  emotion?: string // for steerable TTS
  style?: string // professional, conversational, dramatic, etc.
  language?: string
  ssml?: boolean // use SSML tags
  metadata?: Record<string, any>
}

export interface VoiceGenerationResponse {
  id: string
  status: 'pending' | 'processing' | 'completed' | 'failed'
  text: string
  provider: VoiceProvider
  voice: string
  audioUrl?: string
  r2Key?: string
  duration?: number // seconds
  error?: string
  createdAt: string
  completedAt?: string
  metadata?: Record<string, any>
}

export interface BatchVoiceGenerationRequest {
  voices: Array<{
    text: string
    provider?: VoiceProvider
    voice?: string
    model?: string
    format?: AudioFormat
    speed?: number
    pitch?: number
    emotion?: string
    style?: string
  }>
  metadata?: Record<string, any>
}

export interface BatchVoiceGenerationResponse {
  batchId: string
  voices: VoiceGenerationResponse[]
  total: number
  pending: number
  completed: number
  failed: number
}

export interface VoiceRecord {
  id: string
  text: string
  provider: string
  voice: string
  model: string | null
  format: string
  status: string
  audioUrl: string | null
  r2Key: string | null
  duration: number | null
  error: string | null
  createdAt: string
  completedAt: string | null
  metadata: string | null
}

export interface VoicePromptTemplate {
  name: string
  useCase: string
  text: string
  provider: VoiceProvider
  voice: string
  style?: string
  emotion?: string
}

// ============================================================================
// Validation Schemas
// ============================================================================

import { z } from 'zod'

export const providerSchema = z.enum(['openai', 'elevenlabs', 'google']).default('openai')
export const formatSchema = z.enum(['mp3', 'wav', 'opus', 'aac', 'flac']).default('mp3')

export const voiceGenerationRequestSchema = z.object({
  text: z.string().min(1).max(10000),
  provider: providerSchema.optional(),
  voice: z.string().optional(),
  model: z.string().optional(),
  format: formatSchema.optional(),
  speed: z.number().min(0.25).max(4.0).optional(),
  pitch: z.number().min(-20).max(20).optional(),
  emotion: z.string().max(200).optional(),
  style: z.string().max(200).optional(),
  language: z.string().max(10).optional(),
  ssml: z.boolean().optional(),
  metadata: z.record(z.any()).optional(),
})

export const batchVoiceGenerationRequestSchema = z.object({
  voices: z.array(
    z.object({
      text: z.string().min(1).max(10000),
      provider: providerSchema.optional(),
      voice: z.string().optional(),
      model: z.string().optional(),
      format: formatSchema.optional(),
      speed: z.number().min(0.25).max(4.0).optional(),
      pitch: z.number().min(-20).max(20).optional(),
      emotion: z.string().max(200).optional(),
      style: z.string().max(200).optional(),
    })
  ).min(1).max(10),
  metadata: z.record(z.any()).optional(),
})

export const voicePromptTemplateSchema = z.object({
  name: z.string(),
  useCase: z.string(),
  text: z.string(),
  provider: providerSchema,
  voice: z.string(),
  style: z.string().optional(),
  emotion: z.string().optional(),
})

// ============================================================================
// Voice Prompt Templates
// ============================================================================

/**
 * Template-based prompts covering diverse voiceover use cases
 */
export const voicePromptTemplates: VoicePromptTemplate[] = [
  {
    name: 'Professional Business Narration',
    useCase: 'Corporate video, product demo, explainer video',
    text: `Welcome to the future of business automation. Our AI-powered platform streamlines your workflow, eliminates repetitive tasks, and empowers your team to focus on what truly matters: innovation and growth. With seamless integrations, real-time analytics, and enterprise-grade security, we're helping companies worldwide transform their operations and achieve unprecedented efficiency.`,
    provider: 'openai',
    voice: 'onyx',
    style: 'professional',
    emotion: 'confident and authoritative',
  },
  {
    name: 'Educational Explainer',
    useCase: 'E-learning, tutorial, online course',
    text: `Let's dive into the fascinating world of machine learning! Imagine teaching a computer to recognize patterns, just like how you learned to identify animals as a child. Machine learning algorithms analyze thousands of examples, gradually improving their accuracy with each iteration. Today, we'll explore three fundamental concepts: supervised learning, where we provide labeled data; unsupervised learning, where the algorithm finds patterns on its own; and reinforcement learning, where it learns through trial and error. Ready to get started?`,
    provider: 'elevenlabs',
    voice: 'rachel',
    style: 'educational',
    emotion: 'enthusiastic and engaging',
  },
  {
    name: 'Podcast Intro',
    useCase: 'Podcast opener, show introduction',
    text: `Hey everyone, welcome back to Tech Horizons, the podcast where we explore the cutting edge of technology and its impact on society. I'm your host, and today we have an incredible episode lined up. We'll be discussing the latest breakthroughs in quantum computing, interviewing a pioneer in sustainable AI, and answering your burning questions about the future of work. So grab your coffee, settle in, and let's explore what's next in the world of innovation.`,
    provider: 'openai',
    voice: 'nova',
    style: 'conversational',
    emotion: 'warm and welcoming',
  },
  {
    name: 'Audiobook Excerpt',
    useCase: 'Audiobook narration, storytelling',
    text: `The rain hammered against the window panes as Sarah stood in the dimly lit study, her fingers tracing the worn leather binding of the ancient journal. Three generations had passed since her great-grandmother first penned these words, yet the secrets within still held the power to change everything. She took a deep breath, opened the cover, and began to read. "If you're reading this," the first entry began, "then you've already discovered that our family's past is far more extraordinary than you ever imagined."`,
    provider: 'elevenlabs',
    voice: 'sarah',
    style: 'narrative',
    emotion: 'mysterious and dramatic',
  },
  {
    name: 'Customer Service Greeting',
    useCase: 'IVR system, customer support, helpdesk',
    text: `Thank you for calling TechSupport Solutions. We're here to help you resolve any technical issues you might be experiencing. To better assist you, please listen carefully to the following options. Press one for account and billing inquiries. Press two for technical support and troubleshooting. Press three to speak with a customer service representative. Or, stay on the line to hear these options again. Your call is important to us.`,
    provider: 'google',
    voice: 'en-US-Neural2-C',
    style: 'professional',
    emotion: 'helpful and patient',
  },
]

/**
 * Generate complete voice generation config from a template
 */
export function generateVoiceFromTemplate(template: VoicePromptTemplate) {
  return {
    text: template.text,
    provider: template.provider,
    voice: template.voice,
    style: template.style,
    emotion: template.emotion,
    metadata: {
      template: template.name,
      useCase: template.useCase,
    },
  }
}

/**
 * Get a random voice prompt template
 */
export function getRandomVoicePromptTemplate(): VoicePromptTemplate {
  return voicePromptTemplates[Math.floor(Math.random() * voicePromptTemplates.length)]
}

/**
 * Get all 5 default prompts
 */
export function getAllVoicePromptTemplates(): VoicePromptTemplate[] {
  return voicePromptTemplates
}

/**
 * Generate 5 diverse voice generation configs (one from each template)
 */
export function generateBatchVoicePrompts() {
  return voicePromptTemplates.map(generateVoiceFromTemplate)
}

/**
 * Generate N random voice configs (may include duplicates)
 */
export function generateRandomVoicePrompts(count: number) {
  const prompts = []
  for (let i = 0; i < count; i++) {
    const template = getRandomVoicePromptTemplate()
    prompts.push(generateVoiceFromTemplate(template))
  }
  return prompts
}

/**
 * Add SSML tags for enhanced control (Google Cloud TTS)
 */
export function wrapWithSSML(text: string, options?: { speed?: number; pitch?: number; emphasis?: string }) {
  let ssml = '<speak>'

  if (options?.speed || options?.pitch) {
    const attrs: string[] = []
    if (options.speed) attrs.push(`rate="${options.speed >= 1 ? 'fast' : 'slow'}"`)
    if (options.pitch) attrs.push(`pitch="${options.pitch > 0 ? '+' : ''}${options.pitch}st"`)
    ssml += `<prosody ${attrs.join(' ')}>`
  }

  // Add emphasis if specified
  if (options?.emphasis) {
    ssml += `<emphasis level="${options.emphasis}">${text}</emphasis>`
  } else {
    ssml += text
  }

  if (options?.speed || options?.pitch) {
    ssml += '</prosody>'
  }

  ssml += '</speak>'
  return ssml
}

/**
 * Generate instruction for OpenAI's steerable TTS
 */
export function generateSteerableInstruction(style?: string, emotion?: string): string | undefined {
  if (!style && !emotion) return undefined

  const parts: string[] = []

  if (style) {
    parts.push(`speak in a ${style} style`)
  }

  if (emotion) {
    parts.push(`with a ${emotion} tone`)
  }

  return `Please ${parts.join(', ')}.`
}

// ============================================================================
// Voice Service RPC Interface
// ============================================================================

/**
 * Voice Service RPC Interface
 */
export class VoiceService extends WorkerEntrypoint<Env> {
  /**
   * Generate a single voiceover
   */
  async generateVoice(request: VoiceGenerationRequest): Promise<VoiceGenerationResponse> {
    const validated = voiceGenerationRequestSchema.parse(request)
    const id = ulid()

    try {
      // Store initial record in database
      await this.env.DB.execute(
        `INSERT INTO voice_generations (id, text, provider, voice, model, format, status, created_at, metadata)
         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)`,
        [
          id,
          validated.text,
          validated.provider || 'openai',
          validated.voice || 'default',
          validated.model || null,
          validated.format || 'mp3',
          'pending',
          new Date().toISOString(),
          JSON.stringify(validated.metadata || {}),
        ]
      )

      // Start voice generation (async - will be processed in background)
      this.ctx.waitUntil(this.processVoiceGeneration(id, validated))

      return {
        id,
        status: 'pending',
        text: validated.text,
        provider: validated.provider || 'openai',
        voice: validated.voice || 'default',
        createdAt: new Date().toISOString(),
        metadata: validated.metadata,
      }
    } catch (error: any) {
      console.error('Failed to start voice generation:', error)
      throw new Error(`Voice generation failed: ${error.message}`)
    }
  }

  /**
   * Generate multiple voiceovers in batch
   */
  async generateBatch(request: BatchVoiceGenerationRequest): Promise<BatchVoiceGenerationResponse> {
    const validated = batchVoiceGenerationRequestSchema.parse(request)
    const batchId = ulid()

    const voices: VoiceGenerationResponse[] = []

    for (const voiceConfig of validated.voices) {
      const voice = await this.generateVoice({
        ...voiceConfig,
        metadata: { ...validated.metadata, batchId },
      })
      voices.push(voice)
    }

    return {
      batchId,
      voices,
      total: voices.length,
      pending: voices.filter((v) => v.status === 'pending').length,
      completed: 0,
      failed: 0,
    }
  }

  /**
   * Generate 5 test voiceovers using default prompts
   */
  async generateTestBatch(): Promise<BatchVoiceGenerationResponse> {
    const prompts = generateBatchVoicePrompts()

    return this.generateBatch({
      voices: prompts.map((prompt) => ({
        ...prompt,
      })),
      metadata: {
        type: 'test_batch',
        generatedAt: new Date().toISOString(),
      },
    })
  }

  /**
   * Get voice generation status by ID
   */
  async getVoice(id: string): Promise<VoiceGenerationResponse | null> {
    const result = await this.env.DB.execute(`SELECT * FROM voice_generations WHERE id = ?`, [id])

    if (!result.rows.length) {
      return null
    }

    const row = result.rows[0] as any

    return {
      id: row.id,
      status: row.status,
      text: row.text,
      provider: row.provider,
      voice: row.voice,
      audioUrl: row.audio_url,
      r2Key: row.r2_key,
      duration: row.duration,
      error: row.error,
      createdAt: row.created_at,
      completedAt: row.completed_at,
      metadata: row.metadata ? JSON.parse(row.metadata) : undefined,
    }
  }

  /**
   * Process voice generation in background
   */
  private async processVoiceGeneration(id: string, request: VoiceGenerationRequest): Promise<void> {
    try {
      // Update status to processing
      await this.env.DB.execute(`UPDATE voice_generations SET status = ? WHERE id = ?`, ['processing', id])

      // Call appropriate provider
      const audioData = await this.callVoiceProvider(request)

      // Upload to R2
      const format = request.format || 'mp3'
      const r2Key = `voice/${new Date().getFullYear()}/${new Date().getMonth() + 1}/${id}.${format}`
      await this.env.AUDIO.put(r2Key, audioData)

      // Generate public URL
      const audioUrl = `https://audio.services.do/${r2Key}`

      // TODO: Calculate audio duration from file
      const duration = null

      // Update database with completion
      await this.env.DB.execute(
        `UPDATE voice_generations SET status = ?, audio_url = ?, r2_key = ?, duration = ?, completed_at = ? WHERE id = ?`,
        ['completed', audioUrl, r2Key, duration, new Date().toISOString(), id]
      )
    } catch (error: any) {
      console.error('Voice generation failed:', error)
      await this.env.DB.execute(`UPDATE voice_generations SET status = ?, error = ? WHERE id = ?`, ['failed', error.message, id])
    }
  }

  /**
   * Call appropriate voice provider based on request
   */
  private async callVoiceProvider(request: VoiceGenerationRequest): Promise<ArrayBuffer> {
    const provider = request.provider || 'openai'

    switch (provider) {
      case 'openai':
        return await this.callOpenAITTS(request)
      case 'elevenlabs':
        return await this.callElevenLabsTTS(request)
      case 'google':
        return await this.callGoogleCloudTTS(request)
      default:
        throw new Error(`Unknown provider: ${provider}`)
    }
  }

  /**
   * Call OpenAI TTS API
   */
  private async callOpenAITTS(request: VoiceGenerationRequest): Promise<ArrayBuffer> {
    // TODO: Implement actual OpenAI TTS API call
    // Research shows this structure:
    //
    // const response = await fetch('https://api.openai.com/v1/audio/speech', {
    //   method: 'POST',
    //   headers: {
    //     'Authorization': `Bearer ${this.env.OPENAI_API_KEY}`,
    //     'Content-Type': 'application/json',
    //   },
    //   body: JSON.stringify({
    //     model: request.model || 'tts-1',
    //     input: request.text,
    //     voice: request.voice || 'alloy',
    //     response_format: request.format || 'mp3',
    //     speed: request.speed || 1.0,
    //     instructions: generateSteerableInstruction(request.style, request.emotion)
    //   })
    // })
    //
    // return await response.arrayBuffer()

    throw new Error('OpenAI TTS API integration not yet implemented - requires API key setup')
  }

  /**
   * Call ElevenLabs TTS API
   */
  private async callElevenLabsTTS(request: VoiceGenerationRequest): Promise<ArrayBuffer> {
    // TODO: Implement actual ElevenLabs API call
    // Research shows this structure:
    //
    // const voiceId = request.voice || 'default-voice-id'
    // const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
    //   method: 'POST',
    //   headers: {
    //     'xi-api-key': this.env.ELEVENLABS_API_KEY,
    //     'Content-Type': 'application/json',
    //   },
    //   body: JSON.stringify({
    //     text: request.text,
    //     model_id: request.model || 'eleven_multilingual_v2',
    //     voice_settings: {
    //       stability: 0.5,
    //       similarity_boost: 0.75,
    //       style: request.style ? 0.5 : 0,
    //       use_speaker_boost: true
    //     }
    //   })
    // })
    //
    // return await response.arrayBuffer()

    throw new Error('ElevenLabs API integration not yet implemented - requires API key setup')
  }

  /**
   * Call Google Cloud TTS API
   */
  private async callGoogleCloudTTS(request: VoiceGenerationRequest): Promise<ArrayBuffer> {
    // TODO: Implement actual Google Cloud TTS API call
    // Research shows this structure:
    //
    // const text = request.ssml ? wrapWithSSML(request.text, { speed: request.speed, pitch: request.pitch }) : request.text
    //
    // const response = await fetch('https://texttospeech.googleapis.com/v1/text:synthesize', {
    //   method: 'POST',
    //   headers: {
    //     'Authorization': `Bearer ${this.env.GOOGLE_CLOUD_API_KEY}`,
    //     'Content-Type': 'application/json',
    //   },
    //   body: JSON.stringify({
    //     input: request.ssml ? { ssml: text } : { text },
    //     voice: {
    //       languageCode: request.language || 'en-US',
    //       name: request.voice || 'en-US-Neural2-C'
    //     },
    //     audioConfig: {
    //       audioEncoding: request.format?.toUpperCase() || 'MP3',
    //       speakingRate: request.speed || 1.0,
    //       pitch: request.pitch || 0.0
    //     }
    //   })
    // })
    //
    // const data = await response.json()
    // return Buffer.from(data.audioContent, 'base64')

    throw new Error('Google Cloud TTS API integration not yet implemented - requires API key setup')
  }
}

// ============================================================================
// HTTP API
// ============================================================================

const app = new Hono<{ Bindings: Env }>()

// Health check
app.get('/health', (c) => c.json({ status: 'ok', service: 'voice', version: '1.0.0' }))

// Generate single voiceover
app.post('/generate', async (c) => {
  const service = new VoiceService(c.env.ctx, c.env)
  const body = await c.req.json()
  const result = await service.generateVoice(body)
  return c.json(result)
})

// Generate batch
app.post('/generate/batch', async (c) => {
  const service = new VoiceService(c.env.ctx, c.env)
  const body = await c.req.json()
  const result = await service.generateBatch(body)
  return c.json(result)
})

// Generate test batch (5 default prompts)
app.post('/generate/test', async (c) => {
  const service = new VoiceService(c.env.ctx, c.env)
  const result = await service.generateTestBatch()
  return c.json(result)
})

// Get voice by ID
app.get('/voices/:id', async (c) => {
  const service = new VoiceService(c.env.ctx, c.env)
  const id = c.req.param('id')
  const result = await service.getVoice(id)

  if (!result) {
    return c.json({ error: 'Voice not found' }, 404)
  }

  return c.json(result)
})

// List all voice prompts
app.get('/prompts', (c) => {
  const templates = getAllVoicePromptTemplates()
  const prompts = templates.map((t) => ({
    template: t,
    config: generateVoiceFromTemplate(t),
  }))
  return c.json(prompts)
})

// List available voices by provider
app.get('/voices', (c) => {
  const provider = c.req.query('provider') || 'all'

  const voices = {
    openai: [
      { id: 'alloy', name: 'Alloy', description: 'Neutral and balanced' },
      { id: 'echo', name: 'Echo', description: 'Warm and inclusive' },
      { id: 'fable', name: 'Fable', description: 'Expressive and dynamic' },
      { id: 'onyx', name: 'Onyx', description: 'Deep and authoritative' },
      { id: 'nova', name: 'Nova', description: 'Bright and energetic' },
      { id: 'shimmer', name: 'Shimmer', description: 'Soft and soothing' },
    ],
    elevenlabs: [
      { id: 'rachel', name: 'Rachel', description: 'Clear and professional' },
      { id: 'clyde', name: 'Clyde', description: 'Deep and commanding' },
      { id: 'domi', name: 'Domi', description: 'Warm and friendly' },
    ],
    google: [
      { id: 'en-US-Neural2-A', name: 'US Male 1', description: 'Natural male voice' },
      { id: 'en-US-Neural2-C', name: 'US Female 1', description: 'Natural female voice' },
      { id: 'en-US-Studio-O', name: 'US Studio', description: 'High-quality studio voice' },
    ],
  }

  if (provider === 'all') {
    return c.json(voices)
  } else if (voices[provider as keyof typeof voices]) {
    return c.json(voices[provider as keyof typeof voices])
  } else {
    return c.json({ error: 'Unknown provider' }, 400)
  }
})

export default {
  fetch: app.fetch,
}
```
